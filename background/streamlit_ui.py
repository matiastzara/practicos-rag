import streamlit as st
import yaml
import os
from src.retrievers.retrievers import initialize_rag
from src.chunking.chunking import show_chunks_streamlit


def configure_ui():
    """Configura la interfaz inicial de Streamlit, incluyendo el historial de chat."""
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []

def process_user_query():
    """Procesa la consulta del usuario utilizando el modelo RAG y actualiza el historial de chats."""
    query = st.session_state.get("query", "").strip()
    if not query:
        st.warning("Por favor, ingresa una pregunta v치lida.")
        return

    rag_chain = st.session_state.get("rag_chain")
    if not rag_chain:
        st.error("El modelo RAG no est치 inicializado.")
        return

    # Generar respuesta usando el modelo RAG
    response = rag_chain.invoke(query)

    # Actualizar el historial
    st.session_state["chat_history"].append({"question": query, "response": response})

    # Limpiar el campo de entrada manualmente
    st.session_state["query"] = None

    # Renderizar historial actualizado
    render_chat_history()


def render_chat_interface():
    """Renderiza solo la barra de entrada de texto para interactuar con el chatbot."""
    st.text_input(
        "Haz tu pregunta:",
        placeholder="Escribe tu consulta aqu칤...",
        on_change=process_user_query,
        key="query",
    )


def render_model_selector(config_path="config.yaml"):
    """Renderiza un selector de modelo (super o naive) y actualiza el archivo de configuraci칩n."""
    st.sidebar.markdown("### Selecci칩n de Modelo")
    with open(config_path, "r") as file:
        config = yaml.safe_load(file)

    selected_model = st.sidebar.radio(
        "Selecciona el modelo RAG a utilizar:",
        options=["super", "naive"],
        index=0 if config.get("rag") == "super" else 1,
    )

    if selected_model != config.get("rag"):
        config["rag"] = selected_model
        with open(config_path, "w") as file:
            yaml.safe_dump(config, file)
        st.success(f"Configuraci칩n actualizada: ahora se usa el modelo '{selected_model}'.")


def render_file_uploader(upload_folder="../practicos-rag/data"):
    """Renderiza la bandeja de carga de archivos en la barra lateral y guarda los archivos."""
    st.sidebar.image(
        "background/miauc.png",
        caption="Modelo RAG",
        use_container_width=True,
    )
    st.sidebar.header("Subir documentos")
    uploaded_files = st.sidebar.file_uploader(
        "Selecciona documentos para cargar:",
        type=["pdf", "txt", "docx"],
        accept_multiple_files=True,
    )

    if not os.path.exists(upload_folder):
        os.makedirs(upload_folder)

    if st.sidebar.button("Subir documentos"):
        if uploaded_files:
            for uploaded_file in uploaded_files:
                file_path = os.path.join(upload_folder, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
            st.sidebar.success(f"Se subieron {len(uploaded_files)} archivo(s) correctamente a '{upload_folder}'.")
        else:
            st.sidebar.warning("No se seleccionaron archivos para cargar.")


def safe_initialize_rag(config):
    """Inicializa los componentes RAG de manera segura y los almacena en session_state."""
    if "rag_chain" not in st.session_state:
        try:
            rag_chain, retriever, chunks = initialize_rag(config)
            st.session_state["rag_chain"] = rag_chain
            st.session_state["retriever"] = retriever
            st.session_state["chunks"] = chunks
            st.success("Modelo RAG cargado exitosamente.")
        except Exception as e:
            st.error(f"Error al cargar el modelo RAG: {e}")
            st.session_state["rag_chain"] = None
            st.session_state["retriever"] = None
            st.session_state["chunks"] = []
    return (
        st.session_state.get("rag_chain"),
        st.session_state.get("retriever"),
        st.session_state.get("chunks"),
    )


def render_chat_history():
    """Renderiza el historial de chats en la interfaz con 칤conos para usuario y chatbot."""
    st.markdown("### Historial de Chat")
    for chat in st.session_state["chat_history"]:
        st.markdown(f"游뗵 **Usuario**: {chat['question']}")
        st.markdown(f"游뱄 **Chatbot**: {chat['response']}")